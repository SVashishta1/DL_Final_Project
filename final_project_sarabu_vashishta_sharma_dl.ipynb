{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMpTwGhQD+FGFY/++RVOqI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVashishta1/DL_Final_Project/blob/main/final_project_sarabu_vashishta_sharma_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Wca74R2k6K4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002a8b92-90f4-4286-ab98-9d5b4a406280"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the dataset\n",
        "original_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Original'\n",
        "ground_truth_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Ground Truth'"
      ],
      "metadata": {
        "id": "_qL5EBbF6Djz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, BatchNormalization, Activation, MaxPool2D,\n",
        "    UpSampling2D, Concatenate, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tifffile import imread  # Replacing PIL with tifffile for TIFF images\n",
        "\n",
        "# Load data function\n",
        "def load_data(original_folder, ground_truth_folder, split=0.1):\n",
        "    images = sorted(glob(os.path.join(original_folder, \"*.tif\")))\n",
        "    masks = sorted(glob(os.path.join(ground_truth_folder, \"*.tif\")))\n",
        "\n",
        "    # Split dataset into train, validation, and test sets\n",
        "    train_x, test_x, train_y, test_y = train_test_split(images, masks, test_size=split, random_state=42)\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "# Image reading function (RGB for images)\n",
        "def read_image(path):\n",
        "    if isinstance(path, tf.Tensor):  # Decode TensorFlow tensor\n",
        "        path = path.numpy().decode(\"utf-8\")\n",
        "    elif isinstance(path, bytes):  # Decode bytes\n",
        "        path = path.decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        img = imread(path)  # Read image using tifffile\n",
        "        img = np.expand_dims(img, axis=-1)  # Add channel dimension if missing\n",
        "        img = np.resize(img, (256, 256, 1))  # Resize to target size\n",
        "        img = np.repeat(img, 3, axis=-1)  # Convert grayscale to RGB by repeating the channels\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening image {path}: {e}\")\n",
        "        return np.zeros((256, 256, 3), dtype=np.float32)  # Return a blank image in case of error\n",
        "\n",
        "    x = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return x\n",
        "\n",
        "# Mask reading function (Grayscale for masks)\n",
        "def read_mask(path):\n",
        "    if isinstance(path, tf.Tensor):  # Decode TensorFlow tensor\n",
        "        path = path.numpy().decode(\"utf-8\")\n",
        "    elif isinstance(path, bytes):  # Decode bytes\n",
        "        path = path.decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        img = imread(path)  # Read mask using tifffile\n",
        "        img = np.resize(img, (256, 256, 1))  # Resize to target size\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening mask {path}: {e}\")\n",
        "        return np.zeros((256, 256, 1), dtype=np.float32)  # Return a blank image in case of error\n",
        "\n",
        "    y = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return y\n",
        "\n",
        "# TensorFlow parsing function\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([256, 256, 3])  # RGB input\n",
        "    y.set_shape([256, 256, 1])  # Grayscale mask\n",
        "    return x, y\n",
        "\n",
        "# Dataset preparation function\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n",
        "\n",
        "# UNet model definition\n",
        "def conv_block(x, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model():\n",
        "    size = 256\n",
        "    num_filters = [16, 32, 48, 64]\n",
        "    inputs = Input((size, size, 3))  # RGB input\n",
        "\n",
        "    skip_x = []\n",
        "    x = inputs\n",
        "    ## Encoder\n",
        "    for f in num_filters:\n",
        "        x = conv_block(x, f)\n",
        "        skip_x.append(x)\n",
        "        x = MaxPool2D((2, 2))(x)\n",
        "\n",
        "    ## Bridge\n",
        "    x = conv_block(x, num_filters[-1])\n",
        "\n",
        "    num_filters.reverse()\n",
        "    skip_x.reverse()\n",
        "    ## Decoder\n",
        "    for i, f in enumerate(num_filters):\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        xs = skip_x[i]\n",
        "        x = Concatenate()([x, xs])\n",
        "        x = conv_block(x, f)\n",
        "\n",
        "    ## Output\n",
        "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Evaluation and visualization\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)  # Remove channel dimension\n",
        "    return mask\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to the dataset\n",
        "    original_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Original'\n",
        "    ground_truth_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Ground Truth'\n",
        "\n",
        "    # Load dataset\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(original_folder, ground_truth_folder)\n",
        "\n",
        "    # Hyperparameters\n",
        "    batch_size = 8\n",
        "    epochs = 50\n",
        "    lr = 1e-4\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
        "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
        "\n",
        "    # Model setup\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"model.keras\", save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    # Train model\n",
        "    train_steps = len(train_x) // batch_size\n",
        "    valid_steps = len(valid_x) // batch_size\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate and visualize results\n",
        "    results_dir = \"results/\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    for i, (x_path, y_path) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "        original_image = read_image(x_path)\n",
        "        ground_truth = read_mask(y_path)\n",
        "        predicted_mask = model.predict(np.expand_dims(original_image, axis=0))[0]\n",
        "        predicted_mask = (predicted_mask > 0.5).astype(np.float32)\n",
        "\n",
        "        original_image = np.squeeze(original_image)\n",
        "        ground_truth = mask_parse(ground_truth)\n",
        "        predicted_mask = mask_parse(predicted_mask)\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.imshow(original_image, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "        plt.imshow(ground_truth, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        plt.imshow(predicted_mask, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{results_dir}/{i}.png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVR26UgL45iR",
        "outputId": "7e5e752f-b596-4f97-9ff2-b38d4ab448bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5318 - loss: 0.7646 - precision: 0.0971 - recall: 0.5699"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJe2HNq3EYb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have your test data in 'test_x' and your model predictions in 'predictions'\n",
        "# Load the test images\n",
        "test_data = [read_image(x_path) for x_path in test_x]  # Load test images using the read_image function\n",
        "\n",
        "# Get predictions for the test data\n",
        "predictions = []\n",
        "for image in test_data:\n",
        "    predicted_mask = model.predict(np.expand_dims(image, axis=0))[0]  # Predict the mask\n",
        "    predicted_mask = (predicted_mask > 0.5).astype(np.float32)  # Apply threshold\n",
        "    predictions.append(predicted_mask)\n",
        "\n",
        "# Display images and predictions side by side\n",
        "num_images = 5  # Number of images to display\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(1, num_images, i+1)\n",
        "    image = test_data[i]  # Test image\n",
        "    prediction = predictions[i]  # Predicted mask\n",
        "    plt.imshow(image.squeeze(), cmap=\"gray\")  # Display image (squeeze to remove channel dimension)\n",
        "    plt.title(f\"Pred: {prediction.squeeze()}\")  # Title with predicted label (optional)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5vfJOjY9EmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nb7lBomlEaZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxjvjJ8gEaQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcmWrg2FEaNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTLnuGD8EaKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4_kn70VEaHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VeJFNSxEaEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the dataset\n",
        "original_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Original_jpg'\n",
        "ground_truth_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/GroundTruth_jpg'"
      ],
      "metadata": {
        "id": "P2rl7k3sYsQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, BatchNormalization, Activation, MaxPool2D,\n",
        "    UpSampling2D, Concatenate, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from PIL import Image  # Using PIL to open JPG images\n",
        "\n",
        "# Load data function\n",
        "def load_data(original_folder, ground_truth_folder, split=0.1):\n",
        "    images = sorted(glob(os.path.join(original_folder, \"*.jpg\")))  # Now loading .jpg files\n",
        "    masks = sorted(glob(os.path.join(ground_truth_folder, \"*.jpg\")))  # Now loading .jpg files\n",
        "\n",
        "    # Split dataset into train, validation, and test sets\n",
        "    train_x, test_x, train_y, test_y = train_test_split(images, masks, test_size=split, random_state=42)\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "# Image reading function (RGB for images)\n",
        "def read_image(path):\n",
        "    if isinstance(path, tf.Tensor):  # Decode TensorFlow tensor\n",
        "        path = path.numpy().decode(\"utf-8\")\n",
        "    elif isinstance(path, bytes):  # Decode bytes\n",
        "        path = path.decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        img = Image.open(path)  # Open image using PIL\n",
        "        img = img.convert(\"RGB\")  # Ensure image is in RGB mode\n",
        "        img = np.array(img)  # Convert to numpy array\n",
        "        img = np.resize(img, (256, 256, 3))  # Resize to target size\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening image {path}: {e}\")\n",
        "        return np.zeros((256, 256, 3), dtype=np.float32)  # Return a blank image in case of error\n",
        "\n",
        "    x = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return x\n",
        "\n",
        "# Mask reading function (Grayscale for masks)\n",
        "def read_mask(path):\n",
        "    if isinstance(path, tf.Tensor):  # Decode TensorFlow tensor\n",
        "        path = path.numpy().decode(\"utf-8\")\n",
        "    elif isinstance(path, bytes):  # Decode bytes\n",
        "        path = path.decode(\"utf-8\")\n",
        "\n",
        "    try:\n",
        "        img = Image.open(path)  # Open mask using PIL\n",
        "        img = img.convert(\"L\")  # Convert mask to grayscale\n",
        "        img = np.array(img)  # Convert to numpy array\n",
        "        img = np.resize(img, (256, 256, 1))  # Resize to target size\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening mask {path}: {e}\")\n",
        "        return np.zeros((256, 256, 1), dtype=np.float32)  # Return a blank mask in case of error\n",
        "\n",
        "    y = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return y\n",
        "\n",
        "# TensorFlow parsing function\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([256, 256, 3])  # RGB input\n",
        "    y.set_shape([256, 256, 1])  # Grayscale mask\n",
        "    return x, y\n",
        "\n",
        "# Dataset preparation function\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n",
        "\n",
        "# UNet model definition\n",
        "def conv_block(x, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model():\n",
        "    size = 256\n",
        "    num_filters = [16, 32, 48, 64]\n",
        "    inputs = Input((size, size, 3))  # RGB input\n",
        "\n",
        "    skip_x = []\n",
        "    x = inputs\n",
        "    ## Encoder\n",
        "    for f in num_filters:\n",
        "        x = conv_block(x, f)\n",
        "        skip_x.append(x)\n",
        "        x = MaxPool2D((2, 2))(x)\n",
        "\n",
        "    ## Bridge\n",
        "    x = conv_block(x, num_filters[-1])\n",
        "\n",
        "    num_filters.reverse()\n",
        "    skip_x.reverse()\n",
        "    ## Decoder\n",
        "    for i, f in enumerate(num_filters):\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        xs = skip_x[i]\n",
        "        x = Concatenate()([x, xs])\n",
        "        x = conv_block(x, f)\n",
        "\n",
        "    ## Output\n",
        "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Evaluation and visualization\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)  # Remove channel dimension\n",
        "    return mask\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to the dataset\n",
        "    original_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/Original_jpg'\n",
        "    ground_truth_folder = '/content/drive/MyDrive/dl_final_project_files/CVC-ClinicDB/GroundTruth_jpg'\n",
        "\n",
        "    # Load dataset\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(original_folder, ground_truth_folder)\n",
        "\n",
        "    # Hyperparameters\n",
        "    batch_size = 8\n",
        "    epochs = 50\n",
        "    lr = 1e-4\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
        "    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n",
        "\n",
        "    # Model setup\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"model.keras\", save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    # Train model\n",
        "    train_steps = len(train_x) // batch_size\n",
        "    valid_steps = len(valid_x) // batch_size\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate and visualize results\n",
        "    results_dir = \"results/\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    for i, (x_path, y_path) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "        original_image = read_image(x_path)\n",
        "        ground_truth = read_mask(y_path)\n",
        "        predicted_mask = model.predict(np.expand_dims(original_image, axis=0))[0]\n",
        "        predicted_mask = (predicted_mask > 0.5).astype(np.float32)\n",
        "\n",
        "        original_image = np.squeeze(original_image)\n",
        "        ground_truth = mask_parse(ground_truth)\n",
        "        predicted_mask = mask_parse(predicted_mask)\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(\"Original Image\")\n",
        "        plt.imshow(original_image, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(\"Ground Truth Mask\")\n",
        "        plt.imshow(ground_truth, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        plt.imshow(predicted_mask, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{results_dir}/{i}.png\")\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "Ot5VV9t5YsNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_FZT4u0YsKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3QyQSJqYsHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AK63N0sJYsEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jDQ2Mk_YsB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZgq9S8FYr-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}